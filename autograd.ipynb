{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "# 5.24.4\n",
    "class Sigmoid(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        sig = 1 / (1 + torch.exp(-x))\n",
    "        ctx.save_for_backward(sig)\n",
    "        return sig\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        sig, = ctx.saved_tensors\n",
    "        return grad_output * sig * (1 - sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.4025, -0.3739,  1.0061], requires_grad=True),\n",
       " tensor([0.5993, 0.4076, 0.7323], grad_fn=<SigmoidBackward>),\n",
       " tensor([0.2401, 0.2415, 0.1961]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = Sigmoid.apply(x)\n",
    "y.backward(torch.ones_like(y))\n",
    "x, y, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.6021,  1.2068,  0.6890], requires_grad=True),\n",
       " tensor([0.0000, 1.2068, 0.6890], grad_fn=<ReLUBackward>),\n",
       " tensor([0., 1., 1.]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.24.5\n",
    "class ReLU(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return x.clamp(min=0)\n",
    "       \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        grad = grad_output.clone()\n",
    "        grad[x < 0] = 0\n",
    "        return grad\n",
    "        \n",
    "x = torch.randn(3, requires_grad=True)\n",
    "y = ReLU.apply(x)\n",
    "y.backward(torch.ones_like(y))\n",
    "x, y, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.37 , 0.192, 0.571]), array([0.3884231 , 0.19441289, 0.64900536]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_x = np.array([0.37, 0.192, 0.571])\n",
    "test_y = np.arctanh(test_x)\n",
    "test_x, test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3700, 0.1920, 0.5710], dtype=torch.float64, requires_grad=True),\n",
       " tensor([0.3884, 0.1944, 0.6490], dtype=torch.float64, grad_fn=<ArtanhBackward>),\n",
       " tensor([1.1586, 1.0383, 1.4838], dtype=torch.float64))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.25\n",
    "class Artanh(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return torch.log_(1 + x).sub_(torch.log_(1 - x)).mul_(0.5)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        return grad_output / (1 - torch.pow(x, 2))\n",
    "    \n",
    "x = torch.tensor([0.37, 0.192, 0.571], requires_grad=True, dtype=torch.double)\n",
    "y = Artanh.apply(x)\n",
    "y.backward(torch.ones_like(y))\n",
    "x, y, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.gradcheck(Artanh.apply, torch.tensor(test_x, requires_grad=True, dtype=torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, Array(3., dtype=float32, weak_type=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.27.5\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def jax_fn(x):\n",
    "    return 3 * x + 2\n",
    "\n",
    "jax_fn(2.), jax.grad(jax_fn)(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146.0, Array(54., dtype=float32, weak_type=True))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn2(x):\n",
    "    return 5*x**2 + 4*x + 1\n",
    "fn2(5.), jax.grad(fn2)(5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/latex": [
       "$\\displaystyle \\int\\limits_{0}^{\\infty} \\sqrt{\\frac{1}{x}}\\, dx$"
      ],
      "text/plain": [
       "∞           \n",
       "⌠           \n",
       "⎮     ___   \n",
       "⎮    ╱ 1    \n",
       "⎮   ╱  ─  dx\n",
       "⎮ ╲╱   x    \n",
       "⌡           \n",
       "0           "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "from sympy import *\n",
    "init_printing()\n",
    "x, y, z = symbols('x y z')\n",
    "Integral(sqrt(1/x), (x, 0, oo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
